{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b33ffa1-12e6-4d6b-9ca7-6de3a91e075b",
   "metadata": {},
   "source": [
    "# Analyse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcbc6670-a822-450e-a3b6-c62589ffe36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9408724-28bc-4d12-89ff-52a49bee7402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible : True\n",
      "Nombre de GPU : 1\n",
      "Nom du GPU : NVIDIA GeForce GTX 1650 Ti\n",
      "Version CUDA utilisée par PyTorch : 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA disponible :\", torch.cuda.is_available())\n",
    "print(\"Nombre de GPU :\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nom du GPU :\", torch.cuda.get_device_name(0))\n",
    "    print(\"Version CUDA utilisée par PyTorch :\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0b1eae-d706-4020-b5ee-5a938650fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Niveau de log : DEBUG pour tout voir\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990dfa02-6326-477b-a169-d87ec282659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8274be6-fa8b-4de1-8b47-2737d5520ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409f2a28-8478-4940-a614-8d943e7721f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 26 19:14:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   65C    P0             10W /   50W |     292MiB /   4096MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3528    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     33636    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415b89b8-b7c0-470e-9f95-b8b0aca6a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\matts\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\matts\\anaconda3\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\matts\\anaconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9119972c-2043-4cd8-a7ad-f1ac8966c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "# from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# dataset = load_dataset(\"json\", data_files=\"dataset_big_patent_v3.json\", split=\"train\")\n",
    "\n",
    "# dataset = dataset.remove_columns('query')\n",
    "\n",
    "# # Split en train (80%) et test (20%)\n",
    "# split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "# train_dataset = split_dataset[\"train\"]\n",
    "# test_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d6f97-15d0-4392-8160-a169d6ad10d0",
   "metadata": {},
   "source": [
    "2 versions :\n",
    "https://sbert.net/docs/sentence_transformer/loss_overview.html\n",
    "1. (anchor, positive, negative) triplets -> Ommission de query -> MultipleNegativesRankingLoss\n",
    "2. Create a cutom Loss function for quadruplet -> (anchor, query, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d7e17f-1db9-4727-a23a-a05218b9bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\matts\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\matts\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\matts\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\matts\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matts\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5d83a81-2c25-445f-be2c-148a81d7ed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Matts\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "# 1. Load a model to finetune with 2. (Optional) model card data\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\", # Restart kernel if not working but it is a functionnal V0-> \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    trust_remote_code=True,\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ea144f-057f-4dd4-bab4-9354d4b1ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load a dataset to finetune on\n",
    "dataset = load_dataset(\"json\", data_files=\"dataset_big_patent_v3.json\", split=\"train\")\n",
    "\n",
    "dataset = dataset.remove_columns('query')\n",
    "\n",
    "# Split en train (80%) et test (20%)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ed9dd9-f2b3-4343-bb98-e708d1e3b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a loss function\n",
    "loss = MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660d3c8c-f8e5-49f1-939d-e197697f9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (Optional) Specify training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"models/big-patent-triplet\",\n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,  # Set to False if your GPU can't handle FP16\n",
    "    bf16=False,  # Set to True if your GPU supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # Losses using \"in-batch negatives\" benefit from no duplicates\n",
    "    # Optional tracking/debugging parameters:\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"big-patent-triplet-V1\",  # Used in W&B if `wandb` is installed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d88f92-17b2-45e8-80b4-e8e04f762c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.max_seq_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4861c3f2-fd2f-4d82-a0d8-7c162dda0829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'big-patent-dev_cosine_accuracy': 0.6600000262260437}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. (Optional) Create an evaluator & evaluate the base model\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    anchors=test_dataset[\"anchor\"],\n",
    "    positives=test_dataset[\"positive\"],\n",
    "    negatives=test_dataset[\"negative\"],\n",
    "    name=\"big-patent-dev\",\n",
    "    batch_size=2\n",
    ")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daca8659-92db-4c79-9c4e-2a769f7de2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'V1_eval_triplet_cosine_accuracy': 0.7343358397483826}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# (Optional) Evaluate the trained model on the test set, after training completes\n",
    "triplet_evaluator = TripletEvaluator(\n",
    "    anchors=train_dataset[\"anchor\"],\n",
    "    positives=train_dataset[\"positive\"],\n",
    "    negatives=train_dataset[\"negative\"],\n",
    "    name=\"V1_eval_triplet\"\n",
    ")\n",
    "triplet_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2211710-1f27-475b-bef2-bf92216093e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/big-patent-all-MiniLM-L6-triplet/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2b068-6a02-48a5-83fa-fe69f751d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data vizualisation\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "del df[\"query\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a5099-eaf3-4b56-868c-8ea4d124e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quadruplet original\n",
    "# quadruplet = (\"anchor\", \"query\", \"positive\", \"negative\")\n",
    "\n",
    "# # Transformation\n",
    "# triplet_1 = InputExample(texts=[quadruplet[0], quadruplet[2], quadruplet[3]])  # (anchor, positive, negative)\n",
    "# triplet_2 = InputExample(texts=[quadruplet[1], quadruplet[2], quadruplet[3]])  # (query, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2867c5b-e81c-49da-829a-b53423520614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = triplet_evaluator(model)\n",
    "# print(triplet_evaluator.primary_metric)  # ex: \"mon_eval_triplet_cosine_accuracy\"\n",
    "# print(results[triplet_evaluator.primary_metric])  # ex: 0.92 pour 92% d’exactitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0a689-7fa9-41f9-8a86-9e4cb25ca6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = losses.CachedMultipleNegativesRankingLoss(\n",
    "#     model,\n",
    "#     mini_batch_size=128  # Traite 128 ex. par sous-lot\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93734fa-f422-454d-a9a4-73f8d781d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import is_torch_bf16_gpu_available\n",
    "print(is_torch_bf16_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5d4b6-7401-484a-b3a7-29df645ee309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pendant le fit :\n",
    "# model.fit(\n",
    "#     train_objectives=[...],\n",
    "#     evaluator=evaluator,\n",
    "#     epochs=1,\n",
    "#     evaluation_steps=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800622e-ee40-405d-8b1c-0de80db0977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/blog/train-sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54481072-89a9-4981-93b0-a6496e42c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(dataset):\n",
    "#     texts = [f\"Context: {c}\\nQuestion: {q}\\nAnswer: {a}\" for c, q, a in zip(dataset[\"anchor\"], dataset[\"query\"], dataset[\"positive\"])]\n",
    "#     # Tokenize\n",
    "#     model_inputs = tokenizer(texts, max_length=384, truncation=True, padding=\"max_length\")\n",
    "#     # labels = input_ids\n",
    "#     model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b0d4b-e57a-4473-8bb1-164e907e9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# https://www.learnpytorch.io/pytorch_cheatsheet/\n",
    "# Setup device-agnostic code \n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf393c2-0aa7-4194-8bb0-8264c9b88f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zero-shot performance\n",
    "\n",
    "# prompt = \"Question: How does the crowdsourcing method is used to adjust a video game element ?\\nAnswer:\" # Expected : A processor retrieves a plurality of received game element feedback data from a plurality of users of a game and causes the game element to be adjusted during execution of the game \n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9cbe6-2969-454a-ba42-aa932642832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fine-tuned performance after\n",
    "\n",
    "# prompt = \"Question: How does the crowdsourcing method is used to adjust a video game element ?\\nAnswer:\" # Expected : A processor retrieves a plurality of received game element feedback data from a plurality of users of a game and causes the game element to be adjusted during execution of the game\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "# outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
