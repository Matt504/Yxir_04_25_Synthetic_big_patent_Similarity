{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9779559118236474,
  "eval_steps": 500,
  "global_step": 372,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08016032064128256,
      "grad_norm": 1.144891619682312,
      "learning_rate": 0.00019516129032258066,
      "loss": 2.3545,
      "step": 10
    },
    {
      "epoch": 0.16032064128256512,
      "grad_norm": 1.2809138298034668,
      "learning_rate": 0.00018978494623655916,
      "loss": 2.1632,
      "step": 20
    },
    {
      "epoch": 0.24048096192384769,
      "grad_norm": 7.864643096923828,
      "learning_rate": 0.00018548387096774192,
      "loss": 2.127,
      "step": 30
    },
    {
      "epoch": 0.32064128256513025,
      "grad_norm": 1.7303448915481567,
      "learning_rate": 0.00018010752688172042,
      "loss": 2.1853,
      "step": 40
    },
    {
      "epoch": 0.40080160320641284,
      "grad_norm": 1.2074792385101318,
      "learning_rate": 0.00017473118279569892,
      "loss": 2.1135,
      "step": 50
    },
    {
      "epoch": 0.48096192384769537,
      "grad_norm": 1.1830428838729858,
      "learning_rate": 0.00016935483870967742,
      "loss": 2.1487,
      "step": 60
    },
    {
      "epoch": 0.561122244488978,
      "grad_norm": 1.180973768234253,
      "learning_rate": 0.00016397849462365592,
      "loss": 2.0251,
      "step": 70
    },
    {
      "epoch": 0.6412825651302605,
      "grad_norm": 1.143967866897583,
      "learning_rate": 0.0001586021505376344,
      "loss": 2.2434,
      "step": 80
    },
    {
      "epoch": 0.7214428857715431,
      "grad_norm": 1.290799856185913,
      "learning_rate": 0.0001532258064516129,
      "loss": 1.9581,
      "step": 90
    },
    {
      "epoch": 0.8016032064128257,
      "grad_norm": 1.1973305940628052,
      "learning_rate": 0.0001478494623655914,
      "loss": 2.0695,
      "step": 100
    },
    {
      "epoch": 0.8817635270541082,
      "grad_norm": 1.3090448379516602,
      "learning_rate": 0.0001424731182795699,
      "loss": 2.1467,
      "step": 110
    },
    {
      "epoch": 0.9619238476953907,
      "grad_norm": 1.2389980554580688,
      "learning_rate": 0.00013709677419354837,
      "loss": 2.0726,
      "step": 120
    },
    {
      "epoch": 1.0400801603206413,
      "grad_norm": 1.162561297416687,
      "learning_rate": 0.00013172043010752687,
      "loss": 2.1292,
      "step": 130
    },
    {
      "epoch": 1.1202404809619237,
      "grad_norm": 1.1710333824157715,
      "learning_rate": 0.00012634408602150537,
      "loss": 2.0592,
      "step": 140
    },
    {
      "epoch": 1.2004008016032064,
      "grad_norm": 1.4749703407287598,
      "learning_rate": 0.00012096774193548388,
      "loss": 2.0652,
      "step": 150
    },
    {
      "epoch": 1.280561122244489,
      "grad_norm": 1.2683353424072266,
      "learning_rate": 0.00011559139784946238,
      "loss": 2.1639,
      "step": 160
    },
    {
      "epoch": 1.3607214428857715,
      "grad_norm": 1.293835163116455,
      "learning_rate": 0.00011021505376344086,
      "loss": 2.0358,
      "step": 170
    },
    {
      "epoch": 1.440881763527054,
      "grad_norm": 1.3050506114959717,
      "learning_rate": 0.00010483870967741936,
      "loss": 2.0848,
      "step": 180
    },
    {
      "epoch": 1.5210420841683367,
      "grad_norm": 1.323412537574768,
      "learning_rate": 9.946236559139786e-05,
      "loss": 2.0711,
      "step": 190
    },
    {
      "epoch": 1.6012024048096194,
      "grad_norm": 1.3165972232818604,
      "learning_rate": 9.408602150537636e-05,
      "loss": 2.0716,
      "step": 200
    },
    {
      "epoch": 1.6813627254509018,
      "grad_norm": 1.1421043872833252,
      "learning_rate": 8.870967741935484e-05,
      "loss": 1.9711,
      "step": 210
    },
    {
      "epoch": 1.7615230460921842,
      "grad_norm": 1.1437928676605225,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.9729,
      "step": 220
    },
    {
      "epoch": 1.8416833667334669,
      "grad_norm": 1.2347687482833862,
      "learning_rate": 7.795698924731183e-05,
      "loss": 2.043,
      "step": 230
    },
    {
      "epoch": 1.9218436873747495,
      "grad_norm": 1.3956842422485352,
      "learning_rate": 7.258064516129033e-05,
      "loss": 2.0119,
      "step": 240
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.351083755493164,
      "learning_rate": 6.720430107526882e-05,
      "loss": 1.8732,
      "step": 250
    },
    {
      "epoch": 2.0801603206412826,
      "grad_norm": 1.249626636505127,
      "learning_rate": 6.182795698924732e-05,
      "loss": 2.1554,
      "step": 260
    },
    {
      "epoch": 2.1603206412825653,
      "grad_norm": 1.1659754514694214,
      "learning_rate": 5.645161290322582e-05,
      "loss": 1.913,
      "step": 270
    },
    {
      "epoch": 2.2404809619238475,
      "grad_norm": 1.319932460784912,
      "learning_rate": 5.1075268817204304e-05,
      "loss": 2.0429,
      "step": 280
    },
    {
      "epoch": 2.32064128256513,
      "grad_norm": 1.1926066875457764,
      "learning_rate": 4.56989247311828e-05,
      "loss": 2.063,
      "step": 290
    },
    {
      "epoch": 2.400801603206413,
      "grad_norm": 1.2119126319885254,
      "learning_rate": 4.032258064516129e-05,
      "loss": 1.88,
      "step": 300
    },
    {
      "epoch": 2.4809619238476954,
      "grad_norm": 1.2191869020462036,
      "learning_rate": 3.494623655913979e-05,
      "loss": 1.8834,
      "step": 310
    },
    {
      "epoch": 2.561122244488978,
      "grad_norm": 1.3821074962615967,
      "learning_rate": 2.9569892473118284e-05,
      "loss": 1.9462,
      "step": 320
    },
    {
      "epoch": 2.6412825651302603,
      "grad_norm": 1.325555682182312,
      "learning_rate": 2.4193548387096777e-05,
      "loss": 1.9723,
      "step": 330
    },
    {
      "epoch": 2.721442885771543,
      "grad_norm": 1.3208365440368652,
      "learning_rate": 1.881720430107527e-05,
      "loss": 1.9349,
      "step": 340
    },
    {
      "epoch": 2.8016032064128256,
      "grad_norm": 1.315638542175293,
      "learning_rate": 1.3440860215053763e-05,
      "loss": 2.0417,
      "step": 350
    },
    {
      "epoch": 2.881763527054108,
      "grad_norm": 1.3801724910736084,
      "learning_rate": 8.064516129032258e-06,
      "loss": 2.0971,
      "step": 360
    },
    {
      "epoch": 2.961923847695391,
      "grad_norm": 1.2797808647155762,
      "learning_rate": 2.688172043010753e-06,
      "loss": 2.0921,
      "step": 370
    }
  ],
  "logging_steps": 10,
  "max_steps": 372,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1227202636087296.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
